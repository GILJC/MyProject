{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a43123-53b3-4cb8-b458-8734d872de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056f71dc-b33a-4a6a-8ce6-195ea393189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "# positive, negative한 문장이 섞여있음\n",
    "# -> 긍정, 부정으로 target을 정함\n",
    "targets = [[1], [0], [1], [1], [0], [1]]   # target을 수동으로 맞춰줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ee80a6-d388-41b5-96e8-fa388706b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()   # keras의preprocessing으로 Tokenizer를 만듬\n",
    "tokenizer.fit_on_texts(samples)   # 여기에 samples 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d934b44d-3039-4a5d-b325-25c325b56465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)   # tokenizer에 word_index 찍어보면  ->  단어 사전(dict) 를 보여줌  -> 오늘은 1번, 좋은은 2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1983040-e932-4da3-a9b5-3d0ab60683c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 5, 6], [7, 1, 8, 9], [10, 2, 3, 11], [12, 2, 3, 13], [14, 1, 15, 16], [17, 18, 19, 20]]\n"
     ]
    }
   ],
   "source": [
    "# 저 문장을 실제 index로 바꿔주는 것\n",
    "# 입력 단어 data를 index로 바꿔줌\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "print(sequences)\n",
    "\n",
    "# 결국 sequences <- 얘가 입력 데이터가 됨   /  위의 targets <- 이놈이 target이고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e73640-47e3-47c9-b579-5d51409d3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(sequences)\n",
    "labels = np.array(targets)\n",
    "# 입력과 타겟을 다 numpy배열로 바꾼 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30e3988-6095-4d8e-a1f9-e79b415bc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# 위의 word_index를 이 word_index에 담아둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6308e759-714a-4c6e-a160-ca3880c4184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  1  5  6]\n",
      " [ 7  1  8  9]\n",
      " [10  2  3 11]\n",
      " [12  2  3 13]\n",
      " [14  1 15 16]\n",
      " [17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47934dc7-cd76-4ed9-9767-52dd34799ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20b9af22-bc17-48f6-a1f1-d1be5febbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 둘 다 numpy 배열로 바꾼것 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73941083-467b-487f-8f0d-71fdb9ada3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 변수 선언\n",
    "batch_size = 2\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d420e9a4-bb97-411a-afcc-e993b4bad230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사이즈\n",
    "vocab_size = len(word_index) + 1    # +1 한 이유\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1\n",
    "\n",
    "# hidden_dimension, output_dimension 는 -> Subclassing (Custom Model)의 함수 예제의 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a125998-70b1-4981-97aa-c7565c0ab8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이걸 우리가 쓰던 Sequential 형태로 바꿔보자\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, emb_size, input_length=4))  \n",
    "# vocal_size / 몇차원으로 임베딩 할거냐/ 인풋 렝스는 4로 위에서 고정되어있음\n",
    "model.add(layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)))   # 차원을 하나 줄여주는 역할 -> flatten하고 비슷(안에 있는 데이터는 변형 시키지 않고 찌부러뜨려서 차원을 줄임)\n",
    "# reduce_mean은 평균값을 구한 다음 찌부러트려서 차원을 하나 줄임.  그점이 flatten과 차이점\n",
    "model.add(layers.Dense(hidden_dimension, activation='relu'))\n",
    "model.add(layers.Dense(output_dimension, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(0.001),     # 이런식으로 함수를 직접 쓸 수 있음. -> tf밑에 keras밑에 optimaizers밑에 Adam으로 0.001 넣어줌\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bf6b671-8900-4f00-8d82-716c0456be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 128)            2688      \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dcbfa10-c9db-4fb7-971e-e8b430bb5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output shape의 (None, 4, 128)  <- 출력이 이렇게 나옴\n",
    "\n",
    "# tf.reduce_mean  ->  특정 축으로 평균값을 구함 -> 차원이 하나 줄음\n",
    "# aixs=1 이면 -> 가운데 , 즉 4라는 소리.\n",
    "# \n",
    "# 4,1,5,6이 들어오면 128차원으로 바꿔줌. 그래서 (..4, 128) -> 128이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e49d735a-5502-4a96-abe5-f432ce9c43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 7ms/step - loss: 0.6884 - accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6666 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6487 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6311 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6078 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5566 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3648 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3212 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2354 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1953 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1323 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1072 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.9610e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.6999e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9.4566e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9.1903e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.9319e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7288e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 8.4708e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.2888e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.0598e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.8680e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.6630e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.4736e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.2930e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.1325e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9665e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.8062e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.6415e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.5102e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.3560e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2096e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.0823e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.9409e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 5.8097e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.6856e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.5780e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220467ceaf0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)  # 위에 미리 변수 num_epochs,batch_size 만들어둠\n",
    "# 여기까지가 p40의 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f19b11-d1e4-44de-9549-1670237ef264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7781bf8-de0c-4ea6-afbd-9adac937dd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f5ab3-5461-4e1d-8047-3143059d671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 방법을 subclassing 방법으로 해보겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c52a9144-cfff-4d5e-b79e-f730ef10d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    # 반드시 만들어야한 2개중 1개 = __init__ 함수\n",
    "    def __init__(self, vocab_size, embed_dimension, hidden_dimension, output_dimension):\n",
    "        super(CustomModel, self).__init__(name='my_model')  # class이름을 1번째 인자로 주고, self 주고, .__init__을 호출, 그리고 이름을 자기가 정해서 줌\n",
    "        #우린 embedding, dense layer 2개\n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dimension)\n",
    "        self.dense_layer = layers.Dense(hidden_dimension, activation='relu') #출력은 hidden_dimension으로 잡음\n",
    "        self.output_layer = layers.Dense(output_dimension, activation='sigmoid')\n",
    "        \n",
    "    # 실제로 호출되서 실행되는 부분 -> call 함수\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)  # self.embedding에 입력onputs을 집어넣는다\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.dense_layer(x)  # 출력 x를 담음\n",
    "        x = self.output_layer(x)\n",
    "        # 이러면 출력 결과가 x에 담기고\n",
    "        \n",
    "        # 출력한곳에 x를 반환(return)해주면 됨\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f693d32-64cf-4f33-8346-f0dd30e80443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 0.6894 - accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6695 - accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6534 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6371 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6170 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5928 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5676 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5358 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.4980 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4595 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4139 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3650 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3174 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.2717 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.2276 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1874 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 1.00 - 0s 50ms/step - loss: 0.1538 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1211 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0991 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0788 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0485 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.9823e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.6664e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.4102e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.1315e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.8499e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.5910e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 8.3538e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 8.1258e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.9153e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.7004e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.5031e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.2789e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.0860e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.9088e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.7174e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.5482e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.3890e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.2378e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.0889e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.9259e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.7754e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.6430e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.5108e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.3652e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.2463e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2207bb16eb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = custom model 객체를 만들어 주면 됨\n",
    "model = CustomModel(vocab_size=vocab_size,\n",
    "                   embed_dimension=emb_size,\n",
    "                   hidden_dimension=hidden_dimension,\n",
    "                   output_dimension=output_dimension)\n",
    "# 왼쪽 변수들은 위의 class CustomModel의 __init 안의 변수들,\n",
    "# 오른쪽의 수들은 위의\n",
    "# # 이걸 우리가 쓰던 Sequential 형태로 바꿔보자\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(layers.Embedding(vocab_size, emb_size, ...\n",
    "# model.add(layers.Dense(hidden_dimension, activation='relu'))\n",
    "# model.add(layers.Dense(output_dimension, activation='sigmoid'))\n",
    "# 여기서 가져옴\n",
    "# 여기서 가져와서 하나씩 넣어주면 됨\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# 이 model.compile과, model.fit~~~은\n",
    "# 위에 있는것 그대로 가져왔음..\n",
    "# sequence->subclass 예제이므로, 사용법 익히는중이라, 같은 부분인듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e77b6-1ad0-4422-b722-b8ef0215faeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc2a81-d1e3-4d84-ace7-4e0d3d62c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어 처리 입문 참고 추천\n",
    "# https://wikidocs.net/book/2155"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
